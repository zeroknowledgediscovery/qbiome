{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load ../qbiome/data_formatter.py\n",
    "import pandas as pd\n",
    "\n",
    "class DataFormatter():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "\n",
    "    def load_data(self, fpath_data, fpath_meta, taxon_name='Phylum',\n",
    "    time_column_name='Age (days)', time_column_name_out='day',\n",
    "    k_years=2, k_biomes=15):\n",
    "        \"\"\"\n",
    "        fpath_data:\n",
    "        fpath_meta:\n",
    "        taxon: name of the taxon column, must have proper capitalization\n",
    "        time_column_name: name of the timestamp column in the meta file\n",
    "        time_column_name_out: name of the timestamp column in the data frame produced\n",
    "        k_years:\n",
    "        k_biomes:\n",
    "        \"\"\"\n",
    "        taxa_raw = pd.read_csv(fpath_data)\n",
    "        meta_raw = pd.read_csv(fpath_meta)\n",
    "        taxa_sum = self._sum_taxon(taxa_raw, taxon_name)\n",
    "        meta = self._parse_meta(meta_raw, time_column_name, time_column_name_out)\n",
    "        data = self._join_data_meta(taxa_sum, meta, time_column_name_out)\n",
    "\n",
    "        # depending on the unit of the timestamp in the original data,\n",
    "        # it may be necessary to cut out days beyond 2 or more years\n",
    "        # and to convert days to weeks\n",
    "        data = self._cut_after_k_years(data, k_years)\n",
    "        data = self._convert_days_to_weeks(data)\n",
    "\n",
    "        data = self._use_top_k_biomes(data, k_biomes)\n",
    "        data_qnet = self.pivot_into_qnet_format(data)\n",
    "        return data_qnet\n",
    "\n",
    "    def pivot_into_qnet_format(self, data):\n",
    "        pivoted = data.pivot_table(index=['sample_id', 'week'],\n",
    "        columns=['variable'])['value'].reset_index()\n",
    "        return pivoted\n",
    "\n",
    "    def melt_into_plot_format(self, data):\n",
    "        pass\n",
    "\n",
    "    def _sum_taxon(self, taxa_raw, taxon_name):\n",
    "        taxa = taxa_raw[['Sample ID', taxon_name, 'Relative Abundance']]\n",
    "        taxa_sum = taxa.groupby(by=['Sample ID', taxon_name]).sum()\n",
    "        taxa_sum.reset_index(inplace=True)\n",
    "        taxa_sum.columns = ['sample_id', 'variable', 'value']\n",
    "        print('There are {} unique biomes and {} unique samples'.format(\n",
    "            len(taxa_sum.variable.unique()), len(taxa_sum.sample_id.unique())))\n",
    "        return taxa_sum\n",
    "\n",
    "    def _parse_meta(self, meta_raw, time_column_name, time_column_name_out):\n",
    "        meta = meta_raw[['Sample ID', 'Property', 'Value']]\n",
    "\n",
    "        meta_timestamp = meta[meta['Property'] == time_column_name]\n",
    "        meta_timestamp.drop(columns='Property', inplace=True)\n",
    "        meta_timestamp.columns = ['sample_id', time_column_name_out]\n",
    "\n",
    "        meta_subject_id = meta[meta['Property'] == 'Subject ID']\n",
    "        meta_subject_id.drop(columns='Property', inplace=True)\n",
    "        meta_subject_id.columns = ['sample_id', 'subject_id']\n",
    "\n",
    "        meta = pd.merge(meta_timestamp, meta_subject_id, on='sample_id')\n",
    "        return meta\n",
    "\n",
    "    def _join_data_meta(self, data, meta, time_column_name):\n",
    "        merged = pd.merge(data, meta, how='outer', on='sample_id')\n",
    "        merged.columns = ['sample_id', 'variable', 'value', time_column_name, 'subject_id']\n",
    "        merged.dropna(inplace=True)\n",
    "        merged.loc[:, time_column_name] = pd.to_numeric(merged[time_column_name],\n",
    "        downcast='integer', errors='coerce').astype(int)\n",
    "        # remove negative days\n",
    "        merged = merged[merged[time_column_name] > 0]\n",
    "\n",
    "        print('There are {} unique {}s'.format(\n",
    "            len(merged[time_column_name].unique()), time_column_name))\n",
    "        return merged\n",
    "\n",
    "    def _cut_after_k_years(self, data, k_years):\n",
    "        return data[data.day < 356 * k_years]\n",
    "\n",
    "    def _convert_days_to_weeks(self, data):\n",
    "        weeks = range(data.day.min() - 1, data.day.max() + 8, 7)\n",
    "        print('There are {} unique weeks'.format(len(weeks)))\n",
    "        data = pd.concat([\n",
    "            data.sample_id,\n",
    "            data.subject_id,\n",
    "            data.variable,\n",
    "            pd.cut(pd.Series(data.day), bins=weeks,\n",
    "                        labels=range(1, len(weeks))),\n",
    "            data.value\n",
    "            ], axis=1)\n",
    "        data.columns = ['sample_id', 'subject_id', 'variable', 'week', 'value']\n",
    "        data.week = data.week.astype(int)\n",
    "        return data\n",
    "\n",
    "    def _use_top_k_biomes(self, data, k_biomes):\n",
    "        \"\"\"\n",
    "        Everything except top k is labeled 'unclassified_Bacteria'\n",
    "        \"\"\"\n",
    "        biome_measurement_counts = data.variable.value_counts()\n",
    "        top_k = biome_measurement_counts.nlargest(k_biomes).index\n",
    "        data.loc[~data.variable.isin(top_k), 'variable'] = 'unclassified_Bacteria'\n",
    "        return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirname = '../../infbiome_/data2/'\n",
    "data = dirname + 'SamplesByMetadata_otuDADA2_EMP_10249_ECAM_RSRC_TaxaRelativeAbundance.csv'\n",
    "meta = dirname + 'SamplesByMetadata_otuDADA2_EMP_10249_ECAM_RSRC_Characteristics.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = DataFormatter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 unique biomes and 1216 unique samples\n",
      "There are 311 unique days\n",
      "There are 99 unique weeks\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ruolinzheng/.conda/envs/qnet-dev/lib/python3.7/site-packages/pandas/core/frame.py:4170: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  errors=errors,\n"
     ]
    }
   ],
   "source": [
    "data_qnet = formatter.load_data(data, meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qnet-dev",
   "language": "python",
   "name": "qnet-dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
