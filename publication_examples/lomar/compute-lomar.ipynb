{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate network hypotheses (Local Marginal Regulation/LOMAR coefficients)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "from datetime import datetime\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import qbiome.data_formatter\n",
    "import qbiome.forecaster\n",
    "import qbiome.hypothesis\n",
    "import qbiome.network\n",
    "import qbiome.qnet_orchestrator\n",
    "import qbiome.quantizer\n",
    "import qbiome.qutil\n",
    "import statsmodels.stats.api as sms\n",
    "from quasinet import qnet\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "qnt = qbiome.quantizer.Quantizer(num_levels=26)\n",
    "qnt.load_quantizer_states(\"quantizer.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_hyp(\n",
    "    quant, mod_path_dat, t_start, t_end, causal_cons, no_slf_lps, pref, hyp_dir\n",
    "):\n",
    "    import pathlib\n",
    "    pathlib.Path(hyp_dir).mkdir(parents=True, exist_ok=True)\n",
    "    hyp_dat = qbiome.hypothesis.Hypothesis(quantizer=quant, model_path=mod_path_dat, detailed_labels=True)\n",
    "\n",
    "    hyp_dat.causal_constraint = causal_cons\n",
    "    hyp_dat.no_self_loops = no_slf_lps\n",
    "\n",
    "    hyp_dat.get(time_start=t_start, time_end=t_end)\n",
    "    h_dat_dotfile = (\n",
    "        hyp_dir\n",
    "        + \"/hyp_\"\n",
    "        + pref\n",
    "        + str(t_start)\n",
    "        + \"_\"\n",
    "        + str(t_end)\n",
    "        + \"_\"\n",
    "        + str(causal_cons)\n",
    "        + \".dot\"\n",
    "    )\n",
    "    hyp_dat.to_dot(h_dat_dotfile)\n",
    "    hyp_dat.to_csv(\n",
    "        hyp_dir\n",
    "        + \"/hyp_\"\n",
    "        + pref\n",
    "        + str(t_start)\n",
    "        + \"_\"\n",
    "        + str(t_end)\n",
    "        + \"_\"\n",
    "        + str(causal_cons)\n",
    "        + str(datetime.now())\n",
    "        + \"_netwk.csv\"\n",
    "    )\n",
    "    ntwk_dat_img = (\n",
    "        hyp_dir\n",
    "        + \"/hyp_\"\n",
    "        + pref\n",
    "        + str(t_start)\n",
    "        + \"_\"\n",
    "        + str(t_end)\n",
    "        + \"_\"\n",
    "        + str(causal_cons)\n",
    "        + str(datetime.now())\n",
    "        + \"_netwk.png\"\n",
    "    )\n",
    "    network_dat = qbiome.network.Network(h_dat_dotfile, outfile=ntwk_dat_img)\n",
    "    network_dat.get()\n",
    "\n",
    "    return hyp_dat, ntwk_dat_img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _export_trees(qn, qns, tree_dir):\n",
    "    import pathlib\n",
    "    pathlib.Path(tree_dir + \"/ahcg/\").mkdir(parents=True, exist_ok=True)\n",
    "    pathlib.Path(tree_dir + \"/shcg/\").mkdir(parents=True, exist_ok=True)\n",
    "    for idx, feature_name in enumerate(qn.feature_names):\n",
    "        qnet.export_qnet_tree(\n",
    "            qn,\n",
    "            idx,\n",
    "            os.path.join(tree_dir + \"/ahcg/\", \"{}.dot\".format(feature_name)),\n",
    "            outformat=\"graphviz\",\n",
    "            detailed_output=True,\n",
    "        )\n",
    "\n",
    "    for idx, feature_name in enumerate(qns.feature_names):\n",
    "        qnet.export_qnet_tree(\n",
    "            qns,\n",
    "            idx,\n",
    "            os.path.join(tree_dir + \"/shcg/\", \"{}.dot\".format(feature_name)),\n",
    "            outformat=\"graphviz\",\n",
    "            detailed_output=True,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model_hyps(times, causal_cons, no_slf_lps, appr_df=None, sub_df=None,  quantized=False, quant=None, remove_n=5):\n",
    "    \n",
    "    def _get_quantizer(data, num_levels=26):\n",
    "        \"\"\"\n",
    "        Construct a quantizer from provided `data`\n",
    "        \"\"\"\n",
    "        quantizer = qbiome.quantizer.Quantizer(num_levels=num_levels)\n",
    "        if num_levels > 26:\n",
    "            def _get_labels(num_lvls):\n",
    "                import string\n",
    "                lbls = list(string.ascii_uppercase)\n",
    "                for i in range(2, int(np.ceil(num_lvls / 26)) + 1):\n",
    "                    lbls = lbls + [char * i for char in string.ascii_uppercase]\n",
    "\n",
    "                lbls = tuple(lbls[:num_lvls])\n",
    "\n",
    "                return {lbl: idx for idx, lbl in enumerate(lbls)}\n",
    "            quantizer.labels = _get_labels(num_levels)\n",
    "        data_quantized = quantizer.quantize_df(data)\n",
    "        \n",
    "        return quantizer\n",
    "    \n",
    "    def _get_qnet(\n",
    "        data=None, quantized=False, num_levels=26, quantizer=quant, alpha=0.3, min_samples_split=2\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Compute qnet from provided data\n",
    "        \"\"\"\n",
    "        def _long_to_wide(df):\n",
    "            df_ = pd.concat(\n",
    "                [df.subject_id, df.variable + \"_\" + df.week.astype(str), df.value], axis=1\n",
    "            ).rename(columns={0: \"variable\"})\n",
    "            df_ = df_.pivot(index=\"subject_id\", columns=\"variable\")[\n",
    "                \"value\"\n",
    "            ].reset_index()\n",
    "            return df_\n",
    "        if data is None and data_quantized is None:\n",
    "            raise Exception(\"Either data or data_quantized must be provided.\")\n",
    "        if quantizer is None:\n",
    "            quantizer = qbiome.quantizer.Quantizer(num_levels=num_levels)\n",
    "        if num_levels > 26:\n",
    "            def _get_labels(num_lvls):\n",
    "                import string\n",
    "                lbls = list(string.ascii_uppercase)\n",
    "                for i in range(2, int(np.ceil(num_lvls / 26)) + 1):\n",
    "                    lbls = lbls + [char * i for char in string.ascii_uppercase]\n",
    "\n",
    "                lbls = tuple(lbls[:num_lvls])\n",
    "\n",
    "                return {lbl: idx for idx, lbl in enumerate(lbls)}\n",
    "            quantizer.labels = _get_labels(num_levels)\n",
    "        orchestrator = qbiome.qnet_orchestrator.QnetOrchestrator(quantizer)\n",
    "        if quantized is True:\n",
    "            data_quantized = _long_to_wide(data)\n",
    "        features, label_matrix = quantizer.get_qnet_inputs(data_quantized)\n",
    "        orchestrator.train_qnet(\n",
    "            features,\n",
    "            label_matrix,\n",
    "            alpha=alpha,\n",
    "            min_samples_split=min_samples_split,\n",
    "        )\n",
    "\n",
    "        return orchestrator.model\n",
    "    \n",
    "    if quant is None:\n",
    "        quant = _get_quantizer(pd.concat([appr_df, sub_df]))\n",
    "\n",
    "    drop_indices_a = np.random.choice(appr_df.index, remove_n, replace=False)\n",
    "    drop_indices_s = np.random.choice(sub_df.index, remove_n, replace=False)   \n",
    "       \n",
    "\n",
    "    ahcg = _get_qnet(\n",
    "        data=appr_df.drop(drop_indices_a),\n",
    "        quantized=quantized,\n",
    "        quantizer=quant,\n",
    "    )\n",
    "    shcg = _get_qnet(\n",
    "        data=sub_df.drop(drop_indices_s),\n",
    "        quantized=quantized,\n",
    "        quantizer=quant,\n",
    "    )\n",
    "\n",
    "    time = str(datetime.now())\n",
    "    tree_dir = \"trees/\" + time\n",
    "    hyp_dir = \"hyps/\" + time\n",
    "    _export_trees(ahcg, shcg, tree_dir)\n",
    "\n",
    "    for t in times:\n",
    "        gen_hyp(\n",
    "            quant,\n",
    "            tree_dir + \"/ahcg/\",\n",
    "            t[0],\n",
    "            t[1],\n",
    "            causal_cons,\n",
    "            no_slf_lps,\n",
    "            \"ahcg\",\n",
    "            hyp_dir,\n",
    "        )\n",
    "        gen_hyp(\n",
    "            quant,\n",
    "            tree_dir + \"/shcg/\",\n",
    "            t[0],\n",
    "            t[1],\n",
    "            causal_cons,\n",
    "            no_slf_lps,\n",
    "            \"shcg\",\n",
    "            hyp_dir,\n",
    "        )"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Generate hypotheses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6a097b2b844e4e4db4a177946f4aa80f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/2 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 91/91 [00:26<00:00,  3.48it/s]\n",
      "100%|██████████| 91/91 [00:23<00:00,  3.93it/s]\n",
      "100%|██████████| 91/91 [00:23<00:00,  3.82it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.34it/s]\n",
      "100%|██████████| 91/91 [00:26<00:00,  3.47it/s]\n",
      "100%|██████████| 91/91 [00:22<00:00,  3.96it/s]\n",
      "100%|██████████| 91/91 [00:23<00:00,  3.82it/s]\n",
      "100%|██████████| 91/91 [00:27<00:00,  3.33it/s]\n"
     ]
    }
   ],
   "source": [
    "causal_constraint = -1\n",
    "no_self_loops = False\n",
    "times = [(27, 29), (30, 32)]\n",
    "drop_n = 15\n",
    "n_runs = 2\n",
    "\n",
    "appr_df = pd.read_csv(\"uchicago_appropriate_cohort_quantized_lng.csv\")\n",
    "sub_df = pd.read_csv(\"uchicago_suboptimal_cohort_quantized_lng.csv\")\n",
    "\n",
    "for i in tqdm(range(n_runs)):\n",
    "    get_model_hyps(times, causal_constraint, no_self_loops, appr_df=appr_df, sub_df=sub_df, quantized=True, quant=qnt, remove_n=drop_n)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read in hypotheses; aggregate/summarize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_a27 = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(df)\n",
    "        for df in glob.glob(\"hyps\" + \"/**/*ahcg27_29*.csv\", recursive=True)\n",
    "    ]\n",
    ")\n",
    "df_a30 = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(df)\n",
    "        for df in glob.glob(\"hyps\" + \"/**/*ahcg30_32*.csv\", recursive=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "df_s27 = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(df)\n",
    "        for df in glob.glob(\"hyps\" + \"/**/*shcg27_29*.csv\", recursive=True)\n",
    "    ]\n",
    ")\n",
    "df_s30 = pd.concat(\n",
    "    [\n",
    "        pd.read_csv(df)\n",
    "        for df in glob.glob(\"hyps\" + \"/**/*shcg30_32*.csv\", recursive=True)\n",
    "    ]\n",
    ")\n",
    "\n",
    "def summarise_df(df, n_runs, conf=0.95):\n",
    "    return df.groupby([\"src\", \"tgt\", \"time_tgt\"], as_index=False).agg(\n",
    "        mean=pd.NamedAgg(\n",
    "            column=\"lomar\",\n",
    "            aggfunc=lambda x: x.reset_index(drop=True)\n",
    "            .reindex(range(n_runs), fill_value=0)\n",
    "            .mean(),\n",
    "        ),\n",
    "        var=pd.NamedAgg(\n",
    "            column=\"lomar\",\n",
    "            aggfunc=lambda x: x.reset_index(drop=True)\n",
    "            .reindex(range(n_runs), fill_value=0)\n",
    "            .var(),\n",
    "        ),\n",
    "        median=pd.NamedAgg(\n",
    "            column=\"lomar\",\n",
    "            aggfunc=lambda x: x.reset_index(drop=True)\n",
    "            .reindex(range(n_runs), fill_value=0)\n",
    "            .median(),\n",
    "        ),\n",
    "        ci=pd.NamedAgg(\n",
    "            column=\"lomar\",\n",
    "            aggfunc=lambda x: sms.DescrStatsW(\n",
    "                x.reset_index(drop=True).reindex(range(n_runs), fill_value=0)\n",
    "            ).tconfint_mean(alpha=1 - conf),\n",
    "        ),\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src</th>\n",
       "      <th>tgt</th>\n",
       "      <th>time_tgt</th>\n",
       "      <th>mean</th>\n",
       "      <th>var</th>\n",
       "      <th>median</th>\n",
       "      <th>ci</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>Coriobacteriia</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>28.0</td>\n",
       "      <td>86.258645</td>\n",
       "      <td>1.488111e+04</td>\n",
       "      <td>86.258645</td>\n",
       "      <td>(-1009.7613627689717, 1182.2786534714637)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>143</th>\n",
       "      <td>unclassified_Proteobacteria</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>28.0</td>\n",
       "      <td>60.212059</td>\n",
       "      <td>7.250984e+03</td>\n",
       "      <td>60.212059</td>\n",
       "      <td>(-704.8546951529498, 825.2788139895696)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>58</th>\n",
       "      <td>Coriobacteriia</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>28.0</td>\n",
       "      <td>8.194095</td>\n",
       "      <td>1.342864e+02</td>\n",
       "      <td>8.194095</td>\n",
       "      <td>(-95.92175236366484, 112.30994213539108)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>unclassified_Proteobacteria</td>\n",
       "      <td>Actinobacteria</td>\n",
       "      <td>28.0</td>\n",
       "      <td>5.743401</td>\n",
       "      <td>6.597330e+01</td>\n",
       "      <td>5.743401</td>\n",
       "      <td>(-67.23342523380732, 78.72022676301059)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>28.0</td>\n",
       "      <td>2.846680</td>\n",
       "      <td>2.138135e-05</td>\n",
       "      <td>2.846680</td>\n",
       "      <td>(2.8051348654683985, 2.8882247904175924)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>unclassified_Bacteria</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.111976</td>\n",
       "      <td>6.045262e-07</td>\n",
       "      <td>-0.111976</td>\n",
       "      <td>(-0.11896199484139601, -0.1049906431832192)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Alphaproteobacteria</td>\n",
       "      <td>27.0</td>\n",
       "      <td>-0.116076</td>\n",
       "      <td>9.167810e-07</td>\n",
       "      <td>-0.116076</td>\n",
       "      <td>(-0.1246781975815983, -0.10747284200047681)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>Clostridia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.343115</td>\n",
       "      <td>3.166840e-05</td>\n",
       "      <td>-0.343115</td>\n",
       "      <td>(-0.3936760597603646, -0.2925544682805387)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Bacteroidia</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-0.683070</td>\n",
       "      <td>3.509337e-04</td>\n",
       "      <td>-0.683070</td>\n",
       "      <td>(-0.8513811236205734, -0.5147584114498466)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>Negativicutes</td>\n",
       "      <td>Gammaproteobacteria</td>\n",
       "      <td>29.0</td>\n",
       "      <td>-7.707655</td>\n",
       "      <td>4.004722e-06</td>\n",
       "      <td>-7.707655</td>\n",
       "      <td>(-7.725635182817232, -7.689675401149348)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>151 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                             src                    tgt  time_tgt       mean   \n",
       "60                Coriobacteriia             Clostridia      28.0  86.258645  \\\n",
       "143  unclassified_Proteobacteria             Clostridia      28.0  60.212059   \n",
       "58                Coriobacteriia         Actinobacteria      28.0   8.194095   \n",
       "139  unclassified_Proteobacteria         Actinobacteria      28.0   5.743401   \n",
       "103                Negativicutes    Gammaproteobacteria      28.0   2.846680   \n",
       "..                           ...                    ...       ...        ...   \n",
       "84           Gammaproteobacteria  unclassified_Bacteria      27.0  -0.111976   \n",
       "70           Gammaproteobacteria    Alphaproteobacteria      27.0  -0.116076   \n",
       "77           Gammaproteobacteria             Clostridia      29.0  -0.343115   \n",
       "102                Negativicutes            Bacteroidia      29.0  -0.683070   \n",
       "104                Negativicutes    Gammaproteobacteria      29.0  -7.707655   \n",
       "\n",
       "              var     median                                           ci  \n",
       "60   1.488111e+04  86.258645    (-1009.7613627689717, 1182.2786534714637)  \n",
       "143  7.250984e+03  60.212059      (-704.8546951529498, 825.2788139895696)  \n",
       "58   1.342864e+02   8.194095     (-95.92175236366484, 112.30994213539108)  \n",
       "139  6.597330e+01   5.743401      (-67.23342523380732, 78.72022676301059)  \n",
       "103  2.138135e-05   2.846680     (2.8051348654683985, 2.8882247904175924)  \n",
       "..            ...        ...                                          ...  \n",
       "84   6.045262e-07  -0.111976  (-0.11896199484139601, -0.1049906431832192)  \n",
       "70   9.167810e-07  -0.116076  (-0.1246781975815983, -0.10747284200047681)  \n",
       "77   3.166840e-05  -0.343115   (-0.3936760597603646, -0.2925544682805387)  \n",
       "102  3.509337e-04  -0.683070   (-0.8513811236205734, -0.5147584114498466)  \n",
       "104  4.004722e-06  -7.707655     (-7.725635182817232, -7.689675401149348)  \n",
       "\n",
       "[151 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summarise_df(df_a27, n_runs).sort_values(by=\"mean\", ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "qbiome",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
