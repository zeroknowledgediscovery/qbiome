<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.10.0" />
<title>qbiome.data_formatter API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#666666;background-color:black;//mix-blend-mode:difference;color:#bbbbbb;z-index:3}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#66bb66;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#66FF66}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:transparent;padding:1px 4px;color:#FFA500;overflow-wrap:break-word}h1 code{background:transparent}pre{overflow-wrap:break-word;background:#111111;word-wrap:break-word;border:0;border-top:1px solid #666;border-bottom:1px solid #666;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#333333;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#aaeeaa;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;color:#bbbbbb;background-color:black;overflow-wrap:break-word}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script async src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.7/latest.js?config=TeX-AMS_CHTML" integrity="sha256-kZafAc6mZvK3W3v1pHOcUix30OHQN6pU/NO2oFkqZVw=" crossorigin></script>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>qbiome.data_formatter</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import pandas as pd
import numpy as np

class DataFormatter:
    &#34;&#34;&#34;Parse raw data into usable format by the Quasinet
    &#34;&#34;&#34;

    def __init__(self):
        pass

    def load_data(self, fpath_data, fpath_meta, taxon_name=&#39;Phylum&#39;, tax_dict={&#39;Class&#39;:&#39;dummy&#39;}, time_column_name=&#39;Age (days)&#39;, time_column_name_out=&#39;day&#39;,
    k_years=2, k_biomes=15):
        &#34;&#34;&#34;Parse and join the data CSV and the metadata CSV

        Output format:

        | sample_id       |   subject_id | variable         |   week |    value |
        |:----------------|-------------:|:-----------------|-------:|---------:|
        | MBSMPL0020-6-10 |            1 | Actinobacteriota |     27 | 0.36665  |
        | MBSMPL0020-6-10 |            1 | Bacteroidota     |     27 | 0.507248 |
        | MBSMPL0020-6-10 |            1 | Campilobacterota |     27 | 0.002032 |
        | MBSMPL0020-6-10 |            1 | Desulfobacterota |     27 | 0.005058 |
        | MBSMPL0020-6-10 |            1 | Firmicutes       |     27 | 0.057767 |

        Args:
            fpath_data (str): file path for the data CSV
            fpath_meta (str): file path for the metadata CSV
            taxon_name (str, optional): name of the taxon column exactly as in the data CSV. this is the base taxonomic level for qnet construction.
            Defaults to &#39;Phylum&#39;.
            tax_dict (dict, optional): dictionary of biomes/taxonomic levels for deviations from taxon_name. entities are considered at the level specified rather than taxon_name. Caution: no validation is performed.
            time_column_name (str, optional): name of the timestamp column exactly as in the metadata CSV. Defaults to &#39;Age (days)&#39;.
            time_column_name_out (str, optional): name of the timestamp column in the return data frame. Defaults to &#39;day&#39;.
            k_years (int, optional): in the return data frame, we keep timestamps up to the number of years specified. Defaults to 2.
            k_biomes (int, optional): in the return data frame, we keep the k most abundant biomes. Defaults to 15.

        Returns:
            pandas.DataFrame: parsed, cleaned data frame, see format above
        &#34;&#34;&#34;
        taxa_raw = pd.read_csv(fpath_data)
        meta_raw = pd.read_csv(fpath_meta)
        taxa_sum = self._sum_taxon(taxa_raw, taxon_name, tax_dict)
        meta = self._parse_meta(meta_raw, time_column_name, time_column_name_out)
        data = self._join_data_meta(taxa_sum, meta, time_column_name_out)

        # depending on the unit of the timestamp in the original data,
        # it may be necessary to cut out days beyond 2 or more years
        # and to convert days to weeks
        if k_years is not None:
            data = self._cut_after_k_years(data, k_years)
        data = self._convert_days_to_weeks(data)

        if k_biomes is not None:
            data = self._use_top_k_biomes(data, k_biomes)

        return data

    def load_meta(self, fpath_meta, property_name=&#39;Antibiotic exposure&#39;,
    property_column_name_out=&#39;antibiotic&#39;):
        &#34;&#34;&#34;Return a mapping between sample_id, subject_id and meta data (ex. use antibiotics or not) in a data frame

        Output format:

        | sample_id        | antibiotic   |   subject_id |
        |:-----------------|:-------------|-------------:|
        | MBSMPL0020-6-1   | No           |            1 |
        | MBSMPL0020-6-10  | Yes          |            1 |
        | MBSMPL0020-6-100 | No           |            5 |
        | MBSMPL0020-6-101 | No           |            5 |
        | MBSMPL0020-6-102 | No           |            5 |

        Args:
            fpath_meta (str): file path for the metadata CSV
            property_name (str, optional): name of the meta data value in the property column. Defaults to &#39;Antibiotic exposure&#39;.
            property_column_name_out (str, optional): name of the meta data column in the return data frame. Defaults to &#39;antibiotic&#39;.

        Returns:
            pandas.DataFrame: sample_id and subject_id to meta data mapping, see format above
        &#34;&#34;&#34;
        meta_raw = pd.read_csv(fpath_meta)
        meta = meta_raw[[&#39;Sample ID&#39;, &#39;Property&#39;, &#39;Value&#39;]]

        meta_property = meta[meta[&#39;Property&#39;] == property_name].drop(columns=&#39;Property&#39;)
        meta_property.columns = [&#39;sample_id&#39;, property_column_name_out]

        meta_subject_id = meta[meta[&#39;Property&#39;] == &#39;Subject ID&#39;].drop(columns=&#39;Property&#39;)
        meta_subject_id.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;]

        sample_id_property = pd.merge(meta_property, meta_subject_id, on=&#39;sample_id&#39;, how=&#39;outer&#39;)
        # make sure subject_id are strings
        sample_id_property.subject_id = sample_id_property.subject_id.astype(str)

        return sample_id_property

    def pivot_into_column_format(self, data):
        &#34;&#34;&#34;Pivot the input data frame from this format:

        | sample_id       |   subject_id | variable         |   week |    value |
        |:----------------|-------------:|:-----------------|-------:|---------:|
        | MBSMPL0020-6-10 |            1 | Actinobacteriota |     27 | 0.36665  |
        | MBSMPL0020-6-10 |            1 | Bacteroidota     |     27 | 0.507248 |
        | MBSMPL0020-6-10 |            1 | Campilobacterota |     27 | 0.002032 |
        | MBSMPL0020-6-10 |            1 | Desulfobacterota |     27 | 0.005058 |
        | MBSMPL0020-6-10 |            1 | Firmicutes       |     27 | 0.057767 |

        Into this format where each column is a biome:

        | sample_id         |   week |   Acidobacteriota |   Actinobacteriota |   Bacteroidota |
        |:------------------|-------:|------------------:|-------------------:|---------------:|
        | MBSMPL0020-6-421  |      1 |               nan |           0.011904 |       0.043808 |
        | MBSMPL0020-6-777  |      1 |               nan |           9.8e-05  |       0.000686 |
        | MBSMPL0020-6-1123 |      1 |               nan |           0.005603 |       0.201417 |
        | MBSMPL0020-6-1191 |      1 |               nan |           0.002578 |       0.368164 |
        | MBSMPL0020-6-263  |      1 |               nan |           0.004344 |       0.000381 |

        Args:
            data (pandas.DataFrame): see format above

        Returns:
            pandas.DataFrame: see format above
        &#34;&#34;&#34;
        # keep sample_id in here for later cohort identification
        pivoted = data.pivot_table(
            index=[&#39;sample_id&#39;, &#39;week&#39;], columns=[&#39;variable&#39;])[&#39;value&#39;].reset_index()
        pivoted.sort_values(by=[&#39;week&#39;], inplace=True)
        pivoted.reset_index(drop=True, inplace=True)
        return pivoted

    def melt_into_plot_format(self, data):
        &#34;&#34;&#34;Melt the data into a format `seaborn` can plot easily
        From format:

        | sample_id         |   week |   Acidobacteriota |   Actinobacteriota |   Bacteroidota |
        |:------------------|-------:|------------------:|-------------------:|---------------:|
        | MBSMPL0020-6-421  |      1 |               nan |           0.011904 |       0.043808 |
        | MBSMPL0020-6-777  |      1 |               nan |           9.8e-05  |       0.000686 |
        | MBSMPL0020-6-1123 |      1 |               nan |           0.005603 |       0.201417 |
        | MBSMPL0020-6-1191 |      1 |               nan |           0.002578 |       0.368164 |
        | MBSMPL0020-6-263  |      1 |               nan |           0.004344 |       0.000381 |

        Into format:

        | sample_id         |   week | variable        |   value |
        |:------------------|-------:|:----------------|--------:|
        | MBSMPL0020-6-421  |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-777  |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-1123 |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-1191 |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-263  |      1 | Acidobacteriota |     nan |

        Args:
            data (pandas.DataFrame): see format above

        Returns:
            pandas.DataFrame: see format above
        &#34;&#34;&#34;
        melted = data.melt(id_vars=[&#39;sample_id&#39;, &#39;week&#39;])
        return melted

    def _sum_taxon(self, taxa_raw, taxon_name, tax_dict):
        #taxa = taxa_raw[[&#39;Sample ID&#39;, taxon_name, &#39;Relative Abundance&#39;]]
        #taxa_sum = taxa.groupby(by=[&#39;Sample ID&#39;, taxon_name]).sum()

        taxa_raw[&#39;tmp&#39;] = taxa_raw[taxon_name]
        for x in list(tax_dict):
            taxa_raw[&#39;tmp&#39;] = np.where(taxa_raw[x].isin(tax_dict[x]), taxa_raw[x], taxa_raw[&#39;tmp&#39;])
        taxa = taxa_raw[[&#39;Sample ID&#39;, &#39;tmp&#39;, &#39;Relative Abundance&#39;]]
        taxa_sum = taxa.groupby(by=[&#39;Sample ID&#39;, &#39;tmp&#39;]).sum()

        taxa_sum.reset_index(inplace=True)
        taxa_sum.columns = [&#39;sample_id&#39;, &#39;variable&#39;, &#39;value&#39;]
        print(&#39;There are {} unique biomes and {} unique samples&#39;.format(
            len(taxa_sum.variable.unique()), len(taxa_sum.sample_id.unique())))
        return taxa_sum

    def _parse_meta(self, meta_raw, time_column_name, time_column_name_out):
        meta = meta_raw[[&#39;Sample ID&#39;, &#39;Property&#39;, &#39;Value&#39;]]

        meta_timestamp = meta[meta[&#39;Property&#39;] == time_column_name].drop(columns=&#39;Property&#39;)
        meta_timestamp.columns = [&#39;sample_id&#39;, time_column_name_out]

        meta_subject_id = meta[meta[&#39;Property&#39;] == &#39;Subject ID&#39;].drop(columns=&#39;Property&#39;)
        meta_subject_id.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;]

        meta = pd.merge(meta_timestamp, meta_subject_id, on=&#39;sample_id&#39;)
        return meta

    def _join_data_meta(self, data, meta, time_column_name):
        merged = pd.merge(data, meta, how=&#39;outer&#39;, on=&#39;sample_id&#39;)
        merged.columns = [&#39;sample_id&#39;, &#39;variable&#39;, &#39;value&#39;, time_column_name, &#39;subject_id&#39;]
        merged.dropna(inplace=True)
        merged[time_column_name] = pd.to_numeric(merged[time_column_name],
        downcast=&#39;integer&#39;, errors=&#39;coerce&#39;).astype(int)
        # remove negative days
        merged = merged[merged[time_column_name] &gt; 0]

        print(&#39;There are {} unique {}s&#39;.format(
            len(merged[time_column_name].unique()), time_column_name))
        return merged

    def _cut_after_k_years(self, data, k_years):
        return data[data.day &lt; 356 * k_years]

    def _convert_days_to_weeks(self, data):
        weeks = range(data.day.min() - 1, data.day.max() + 8, 7)
        print(&#39;There are {} unique weeks&#39;.format(len(weeks)))
        data = pd.concat([
            data.sample_id,
            data.subject_id,
            data.variable,
            pd.cut(pd.Series(data.day), bins=weeks,
                        labels=range(1, len(weeks))),
            data.value
            ], axis=1)
        data.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;, &#39;variable&#39;, &#39;week&#39;, &#39;value&#39;]
        data.week = data.week.astype(int)
        return data

    def _use_top_k_biomes(self, data, k_biomes):
        &#34;&#34;&#34;
        Everything except top k is labeled &#39;unclassified_Bacteria&#39;
        &#34;&#34;&#34;
        biome_measurement_counts = data.variable.value_counts()
        top_k = biome_measurement_counts.nlargest(k_biomes).index
        data.loc[~data.variable.isin(top_k), &#39;variable&#39;] = &#39;unclassified_Bacteria&#39;
        return data</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="qbiome.data_formatter.DataFormatter"><code class="flex name class">
<span>class <span class="ident">DataFormatter</span></span>
</code></dt>
<dd>
<div class="desc"><p>Parse raw data into usable format by the Quasinet</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class DataFormatter:
    &#34;&#34;&#34;Parse raw data into usable format by the Quasinet
    &#34;&#34;&#34;

    def __init__(self):
        pass

    def load_data(self, fpath_data, fpath_meta, taxon_name=&#39;Phylum&#39;, tax_dict={&#39;Class&#39;:&#39;dummy&#39;}, time_column_name=&#39;Age (days)&#39;, time_column_name_out=&#39;day&#39;,
    k_years=2, k_biomes=15):
        &#34;&#34;&#34;Parse and join the data CSV and the metadata CSV

        Output format:

        | sample_id       |   subject_id | variable         |   week |    value |
        |:----------------|-------------:|:-----------------|-------:|---------:|
        | MBSMPL0020-6-10 |            1 | Actinobacteriota |     27 | 0.36665  |
        | MBSMPL0020-6-10 |            1 | Bacteroidota     |     27 | 0.507248 |
        | MBSMPL0020-6-10 |            1 | Campilobacterota |     27 | 0.002032 |
        | MBSMPL0020-6-10 |            1 | Desulfobacterota |     27 | 0.005058 |
        | MBSMPL0020-6-10 |            1 | Firmicutes       |     27 | 0.057767 |

        Args:
            fpath_data (str): file path for the data CSV
            fpath_meta (str): file path for the metadata CSV
            taxon_name (str, optional): name of the taxon column exactly as in the data CSV. this is the base taxonomic level for qnet construction.
            Defaults to &#39;Phylum&#39;.
            tax_dict (dict, optional): dictionary of biomes/taxonomic levels for deviations from taxon_name. entities are considered at the level specified rather than taxon_name. Caution: no validation is performed.
            time_column_name (str, optional): name of the timestamp column exactly as in the metadata CSV. Defaults to &#39;Age (days)&#39;.
            time_column_name_out (str, optional): name of the timestamp column in the return data frame. Defaults to &#39;day&#39;.
            k_years (int, optional): in the return data frame, we keep timestamps up to the number of years specified. Defaults to 2.
            k_biomes (int, optional): in the return data frame, we keep the k most abundant biomes. Defaults to 15.

        Returns:
            pandas.DataFrame: parsed, cleaned data frame, see format above
        &#34;&#34;&#34;
        taxa_raw = pd.read_csv(fpath_data)
        meta_raw = pd.read_csv(fpath_meta)
        taxa_sum = self._sum_taxon(taxa_raw, taxon_name, tax_dict)
        meta = self._parse_meta(meta_raw, time_column_name, time_column_name_out)
        data = self._join_data_meta(taxa_sum, meta, time_column_name_out)

        # depending on the unit of the timestamp in the original data,
        # it may be necessary to cut out days beyond 2 or more years
        # and to convert days to weeks
        if k_years is not None:
            data = self._cut_after_k_years(data, k_years)
        data = self._convert_days_to_weeks(data)

        if k_biomes is not None:
            data = self._use_top_k_biomes(data, k_biomes)

        return data

    def load_meta(self, fpath_meta, property_name=&#39;Antibiotic exposure&#39;,
    property_column_name_out=&#39;antibiotic&#39;):
        &#34;&#34;&#34;Return a mapping between sample_id, subject_id and meta data (ex. use antibiotics or not) in a data frame

        Output format:

        | sample_id        | antibiotic   |   subject_id |
        |:-----------------|:-------------|-------------:|
        | MBSMPL0020-6-1   | No           |            1 |
        | MBSMPL0020-6-10  | Yes          |            1 |
        | MBSMPL0020-6-100 | No           |            5 |
        | MBSMPL0020-6-101 | No           |            5 |
        | MBSMPL0020-6-102 | No           |            5 |

        Args:
            fpath_meta (str): file path for the metadata CSV
            property_name (str, optional): name of the meta data value in the property column. Defaults to &#39;Antibiotic exposure&#39;.
            property_column_name_out (str, optional): name of the meta data column in the return data frame. Defaults to &#39;antibiotic&#39;.

        Returns:
            pandas.DataFrame: sample_id and subject_id to meta data mapping, see format above
        &#34;&#34;&#34;
        meta_raw = pd.read_csv(fpath_meta)
        meta = meta_raw[[&#39;Sample ID&#39;, &#39;Property&#39;, &#39;Value&#39;]]

        meta_property = meta[meta[&#39;Property&#39;] == property_name].drop(columns=&#39;Property&#39;)
        meta_property.columns = [&#39;sample_id&#39;, property_column_name_out]

        meta_subject_id = meta[meta[&#39;Property&#39;] == &#39;Subject ID&#39;].drop(columns=&#39;Property&#39;)
        meta_subject_id.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;]

        sample_id_property = pd.merge(meta_property, meta_subject_id, on=&#39;sample_id&#39;, how=&#39;outer&#39;)
        # make sure subject_id are strings
        sample_id_property.subject_id = sample_id_property.subject_id.astype(str)

        return sample_id_property

    def pivot_into_column_format(self, data):
        &#34;&#34;&#34;Pivot the input data frame from this format:

        | sample_id       |   subject_id | variable         |   week |    value |
        |:----------------|-------------:|:-----------------|-------:|---------:|
        | MBSMPL0020-6-10 |            1 | Actinobacteriota |     27 | 0.36665  |
        | MBSMPL0020-6-10 |            1 | Bacteroidota     |     27 | 0.507248 |
        | MBSMPL0020-6-10 |            1 | Campilobacterota |     27 | 0.002032 |
        | MBSMPL0020-6-10 |            1 | Desulfobacterota |     27 | 0.005058 |
        | MBSMPL0020-6-10 |            1 | Firmicutes       |     27 | 0.057767 |

        Into this format where each column is a biome:

        | sample_id         |   week |   Acidobacteriota |   Actinobacteriota |   Bacteroidota |
        |:------------------|-------:|------------------:|-------------------:|---------------:|
        | MBSMPL0020-6-421  |      1 |               nan |           0.011904 |       0.043808 |
        | MBSMPL0020-6-777  |      1 |               nan |           9.8e-05  |       0.000686 |
        | MBSMPL0020-6-1123 |      1 |               nan |           0.005603 |       0.201417 |
        | MBSMPL0020-6-1191 |      1 |               nan |           0.002578 |       0.368164 |
        | MBSMPL0020-6-263  |      1 |               nan |           0.004344 |       0.000381 |

        Args:
            data (pandas.DataFrame): see format above

        Returns:
            pandas.DataFrame: see format above
        &#34;&#34;&#34;
        # keep sample_id in here for later cohort identification
        pivoted = data.pivot_table(
            index=[&#39;sample_id&#39;, &#39;week&#39;], columns=[&#39;variable&#39;])[&#39;value&#39;].reset_index()
        pivoted.sort_values(by=[&#39;week&#39;], inplace=True)
        pivoted.reset_index(drop=True, inplace=True)
        return pivoted

    def melt_into_plot_format(self, data):
        &#34;&#34;&#34;Melt the data into a format `seaborn` can plot easily
        From format:

        | sample_id         |   week |   Acidobacteriota |   Actinobacteriota |   Bacteroidota |
        |:------------------|-------:|------------------:|-------------------:|---------------:|
        | MBSMPL0020-6-421  |      1 |               nan |           0.011904 |       0.043808 |
        | MBSMPL0020-6-777  |      1 |               nan |           9.8e-05  |       0.000686 |
        | MBSMPL0020-6-1123 |      1 |               nan |           0.005603 |       0.201417 |
        | MBSMPL0020-6-1191 |      1 |               nan |           0.002578 |       0.368164 |
        | MBSMPL0020-6-263  |      1 |               nan |           0.004344 |       0.000381 |

        Into format:

        | sample_id         |   week | variable        |   value |
        |:------------------|-------:|:----------------|--------:|
        | MBSMPL0020-6-421  |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-777  |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-1123 |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-1191 |      1 | Acidobacteriota |     nan |
        | MBSMPL0020-6-263  |      1 | Acidobacteriota |     nan |

        Args:
            data (pandas.DataFrame): see format above

        Returns:
            pandas.DataFrame: see format above
        &#34;&#34;&#34;
        melted = data.melt(id_vars=[&#39;sample_id&#39;, &#39;week&#39;])
        return melted

    def _sum_taxon(self, taxa_raw, taxon_name, tax_dict):
        #taxa = taxa_raw[[&#39;Sample ID&#39;, taxon_name, &#39;Relative Abundance&#39;]]
        #taxa_sum = taxa.groupby(by=[&#39;Sample ID&#39;, taxon_name]).sum()

        taxa_raw[&#39;tmp&#39;] = taxa_raw[taxon_name]
        for x in list(tax_dict):
            taxa_raw[&#39;tmp&#39;] = np.where(taxa_raw[x].isin(tax_dict[x]), taxa_raw[x], taxa_raw[&#39;tmp&#39;])
        taxa = taxa_raw[[&#39;Sample ID&#39;, &#39;tmp&#39;, &#39;Relative Abundance&#39;]]
        taxa_sum = taxa.groupby(by=[&#39;Sample ID&#39;, &#39;tmp&#39;]).sum()

        taxa_sum.reset_index(inplace=True)
        taxa_sum.columns = [&#39;sample_id&#39;, &#39;variable&#39;, &#39;value&#39;]
        print(&#39;There are {} unique biomes and {} unique samples&#39;.format(
            len(taxa_sum.variable.unique()), len(taxa_sum.sample_id.unique())))
        return taxa_sum

    def _parse_meta(self, meta_raw, time_column_name, time_column_name_out):
        meta = meta_raw[[&#39;Sample ID&#39;, &#39;Property&#39;, &#39;Value&#39;]]

        meta_timestamp = meta[meta[&#39;Property&#39;] == time_column_name].drop(columns=&#39;Property&#39;)
        meta_timestamp.columns = [&#39;sample_id&#39;, time_column_name_out]

        meta_subject_id = meta[meta[&#39;Property&#39;] == &#39;Subject ID&#39;].drop(columns=&#39;Property&#39;)
        meta_subject_id.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;]

        meta = pd.merge(meta_timestamp, meta_subject_id, on=&#39;sample_id&#39;)
        return meta

    def _join_data_meta(self, data, meta, time_column_name):
        merged = pd.merge(data, meta, how=&#39;outer&#39;, on=&#39;sample_id&#39;)
        merged.columns = [&#39;sample_id&#39;, &#39;variable&#39;, &#39;value&#39;, time_column_name, &#39;subject_id&#39;]
        merged.dropna(inplace=True)
        merged[time_column_name] = pd.to_numeric(merged[time_column_name],
        downcast=&#39;integer&#39;, errors=&#39;coerce&#39;).astype(int)
        # remove negative days
        merged = merged[merged[time_column_name] &gt; 0]

        print(&#39;There are {} unique {}s&#39;.format(
            len(merged[time_column_name].unique()), time_column_name))
        return merged

    def _cut_after_k_years(self, data, k_years):
        return data[data.day &lt; 356 * k_years]

    def _convert_days_to_weeks(self, data):
        weeks = range(data.day.min() - 1, data.day.max() + 8, 7)
        print(&#39;There are {} unique weeks&#39;.format(len(weeks)))
        data = pd.concat([
            data.sample_id,
            data.subject_id,
            data.variable,
            pd.cut(pd.Series(data.day), bins=weeks,
                        labels=range(1, len(weeks))),
            data.value
            ], axis=1)
        data.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;, &#39;variable&#39;, &#39;week&#39;, &#39;value&#39;]
        data.week = data.week.astype(int)
        return data

    def _use_top_k_biomes(self, data, k_biomes):
        &#34;&#34;&#34;
        Everything except top k is labeled &#39;unclassified_Bacteria&#39;
        &#34;&#34;&#34;
        biome_measurement_counts = data.variable.value_counts()
        top_k = biome_measurement_counts.nlargest(k_biomes).index
        data.loc[~data.variable.isin(top_k), &#39;variable&#39;] = &#39;unclassified_Bacteria&#39;
        return data</code></pre>
</details>
<h3>Methods</h3>
<dl>
<dt id="qbiome.data_formatter.DataFormatter.load_data"><code class="name flex">
<span>def <span class="ident">load_data</span></span>(<span>self, fpath_data, fpath_meta, taxon_name='Phylum', tax_dict={'Class': 'dummy'}, time_column_name='Age (days)', time_column_name_out='day', k_years=2, k_biomes=15)</span>
</code></dt>
<dd>
<div class="desc"><p>Parse and join the data CSV and the metadata CSV</p>
<p>Output format:</p>
<table>
<thead>
<tr>
<th align="left">sample_id</th>
<th align="right">subject_id</th>
<th align="left">variable</th>
<th align="right">week</th>
<th align="right">value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Actinobacteriota</td>
<td align="right">27</td>
<td align="right">0.36665</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Bacteroidota</td>
<td align="right">27</td>
<td align="right">0.507248</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Campilobacterota</td>
<td align="right">27</td>
<td align="right">0.002032</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Desulfobacterota</td>
<td align="right">27</td>
<td align="right">0.005058</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Firmicutes</td>
<td align="right">27</td>
<td align="right">0.057767</td>
</tr>
</tbody>
</table>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fpath_data</code></strong> :&ensp;<code>str</code></dt>
<dd>file path for the data CSV</dd>
<dt><strong><code>fpath_meta</code></strong> :&ensp;<code>str</code></dt>
<dd>file path for the metadata CSV</dd>
<dt><strong><code>taxon_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>name of the taxon column exactly as in the data CSV. this is the base taxonomic level for qnet construction.</dd>
<dt>Defaults to 'Phylum'.</dt>
<dt><strong><code>tax_dict</code></strong> :&ensp;<code>dict</code>, optional</dt>
<dd>dictionary of biomes/taxonomic levels for deviations from taxon_name. entities are considered at the level specified rather than taxon_name. Caution: no validation is performed.</dd>
<dt><strong><code>time_column_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>name of the timestamp column exactly as in the metadata CSV. Defaults to 'Age (days)'.</dd>
<dt><strong><code>time_column_name_out</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>name of the timestamp column in the return data frame. Defaults to 'day'.</dd>
<dt><strong><code>k_years</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>in the return data frame, we keep timestamps up to the number of years specified. Defaults to 2.</dd>
<dt><strong><code>k_biomes</code></strong> :&ensp;<code>int</code>, optional</dt>
<dd>in the return data frame, we keep the k most abundant biomes. Defaults to 15.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>parsed, cleaned data frame, see format above</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_data(self, fpath_data, fpath_meta, taxon_name=&#39;Phylum&#39;, tax_dict={&#39;Class&#39;:&#39;dummy&#39;}, time_column_name=&#39;Age (days)&#39;, time_column_name_out=&#39;day&#39;,
k_years=2, k_biomes=15):
    &#34;&#34;&#34;Parse and join the data CSV and the metadata CSV

    Output format:

    | sample_id       |   subject_id | variable         |   week |    value |
    |:----------------|-------------:|:-----------------|-------:|---------:|
    | MBSMPL0020-6-10 |            1 | Actinobacteriota |     27 | 0.36665  |
    | MBSMPL0020-6-10 |            1 | Bacteroidota     |     27 | 0.507248 |
    | MBSMPL0020-6-10 |            1 | Campilobacterota |     27 | 0.002032 |
    | MBSMPL0020-6-10 |            1 | Desulfobacterota |     27 | 0.005058 |
    | MBSMPL0020-6-10 |            1 | Firmicutes       |     27 | 0.057767 |

    Args:
        fpath_data (str): file path for the data CSV
        fpath_meta (str): file path for the metadata CSV
        taxon_name (str, optional): name of the taxon column exactly as in the data CSV. this is the base taxonomic level for qnet construction.
        Defaults to &#39;Phylum&#39;.
        tax_dict (dict, optional): dictionary of biomes/taxonomic levels for deviations from taxon_name. entities are considered at the level specified rather than taxon_name. Caution: no validation is performed.
        time_column_name (str, optional): name of the timestamp column exactly as in the metadata CSV. Defaults to &#39;Age (days)&#39;.
        time_column_name_out (str, optional): name of the timestamp column in the return data frame. Defaults to &#39;day&#39;.
        k_years (int, optional): in the return data frame, we keep timestamps up to the number of years specified. Defaults to 2.
        k_biomes (int, optional): in the return data frame, we keep the k most abundant biomes. Defaults to 15.

    Returns:
        pandas.DataFrame: parsed, cleaned data frame, see format above
    &#34;&#34;&#34;
    taxa_raw = pd.read_csv(fpath_data)
    meta_raw = pd.read_csv(fpath_meta)
    taxa_sum = self._sum_taxon(taxa_raw, taxon_name, tax_dict)
    meta = self._parse_meta(meta_raw, time_column_name, time_column_name_out)
    data = self._join_data_meta(taxa_sum, meta, time_column_name_out)

    # depending on the unit of the timestamp in the original data,
    # it may be necessary to cut out days beyond 2 or more years
    # and to convert days to weeks
    if k_years is not None:
        data = self._cut_after_k_years(data, k_years)
    data = self._convert_days_to_weeks(data)

    if k_biomes is not None:
        data = self._use_top_k_biomes(data, k_biomes)

    return data</code></pre>
</details>
</dd>
<dt id="qbiome.data_formatter.DataFormatter.load_meta"><code class="name flex">
<span>def <span class="ident">load_meta</span></span>(<span>self, fpath_meta, property_name='Antibiotic exposure', property_column_name_out='antibiotic')</span>
</code></dt>
<dd>
<div class="desc"><p>Return a mapping between sample_id, subject_id and meta data (ex. use antibiotics or not) in a data frame</p>
<p>Output format:</p>
<table>
<thead>
<tr>
<th align="left">sample_id</th>
<th align="left">antibiotic</th>
<th align="right">subject_id</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MBSMPL0020-6-1</td>
<td align="left">No</td>
<td align="right">1</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="left">Yes</td>
<td align="right">1</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-100</td>
<td align="left">No</td>
<td align="right">5</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-101</td>
<td align="left">No</td>
<td align="right">5</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-102</td>
<td align="left">No</td>
<td align="right">5</td>
</tr>
</tbody>
</table>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>fpath_meta</code></strong> :&ensp;<code>str</code></dt>
<dd>file path for the metadata CSV</dd>
<dt><strong><code>property_name</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>name of the meta data value in the property column. Defaults to 'Antibiotic exposure'.</dd>
<dt><strong><code>property_column_name_out</code></strong> :&ensp;<code>str</code>, optional</dt>
<dd>name of the meta data column in the return data frame. Defaults to 'antibiotic'.</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>sample_id and subject_id to meta data mapping, see format above</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_meta(self, fpath_meta, property_name=&#39;Antibiotic exposure&#39;,
property_column_name_out=&#39;antibiotic&#39;):
    &#34;&#34;&#34;Return a mapping between sample_id, subject_id and meta data (ex. use antibiotics or not) in a data frame

    Output format:

    | sample_id        | antibiotic   |   subject_id |
    |:-----------------|:-------------|-------------:|
    | MBSMPL0020-6-1   | No           |            1 |
    | MBSMPL0020-6-10  | Yes          |            1 |
    | MBSMPL0020-6-100 | No           |            5 |
    | MBSMPL0020-6-101 | No           |            5 |
    | MBSMPL0020-6-102 | No           |            5 |

    Args:
        fpath_meta (str): file path for the metadata CSV
        property_name (str, optional): name of the meta data value in the property column. Defaults to &#39;Antibiotic exposure&#39;.
        property_column_name_out (str, optional): name of the meta data column in the return data frame. Defaults to &#39;antibiotic&#39;.

    Returns:
        pandas.DataFrame: sample_id and subject_id to meta data mapping, see format above
    &#34;&#34;&#34;
    meta_raw = pd.read_csv(fpath_meta)
    meta = meta_raw[[&#39;Sample ID&#39;, &#39;Property&#39;, &#39;Value&#39;]]

    meta_property = meta[meta[&#39;Property&#39;] == property_name].drop(columns=&#39;Property&#39;)
    meta_property.columns = [&#39;sample_id&#39;, property_column_name_out]

    meta_subject_id = meta[meta[&#39;Property&#39;] == &#39;Subject ID&#39;].drop(columns=&#39;Property&#39;)
    meta_subject_id.columns = [&#39;sample_id&#39;, &#39;subject_id&#39;]

    sample_id_property = pd.merge(meta_property, meta_subject_id, on=&#39;sample_id&#39;, how=&#39;outer&#39;)
    # make sure subject_id are strings
    sample_id_property.subject_id = sample_id_property.subject_id.astype(str)

    return sample_id_property</code></pre>
</details>
</dd>
<dt id="qbiome.data_formatter.DataFormatter.melt_into_plot_format"><code class="name flex">
<span>def <span class="ident">melt_into_plot_format</span></span>(<span>self, data)</span>
</code></dt>
<dd>
<div class="desc"><p>Melt the data into a format <code>seaborn</code> can plot easily
From format:</p>
<table>
<thead>
<tr>
<th align="left">sample_id</th>
<th align="right">week</th>
<th align="right">Acidobacteriota</th>
<th align="right">Actinobacteriota</th>
<th align="right">Bacteroidota</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MBSMPL0020-6-421</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.011904</td>
<td align="right">0.043808</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-777</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">9.8e-05</td>
<td align="right">0.000686</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-1123</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.005603</td>
<td align="right">0.201417</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-1191</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.002578</td>
<td align="right">0.368164</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-263</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.004344</td>
<td align="right">0.000381</td>
</tr>
</tbody>
</table>
<p>Into format:</p>
<table>
<thead>
<tr>
<th align="left">sample_id</th>
<th align="right">week</th>
<th align="left">variable</th>
<th align="right">value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MBSMPL0020-6-421</td>
<td align="right">1</td>
<td align="left">Acidobacteriota</td>
<td align="right">nan</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-777</td>
<td align="right">1</td>
<td align="left">Acidobacteriota</td>
<td align="right">nan</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-1123</td>
<td align="right">1</td>
<td align="left">Acidobacteriota</td>
<td align="right">nan</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-1191</td>
<td align="right">1</td>
<td align="left">Acidobacteriota</td>
<td align="right">nan</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-263</td>
<td align="right">1</td>
<td align="left">Acidobacteriota</td>
<td align="right">nan</td>
</tr>
</tbody>
</table>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>see format above</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>see format above</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def melt_into_plot_format(self, data):
    &#34;&#34;&#34;Melt the data into a format `seaborn` can plot easily
    From format:

    | sample_id         |   week |   Acidobacteriota |   Actinobacteriota |   Bacteroidota |
    |:------------------|-------:|------------------:|-------------------:|---------------:|
    | MBSMPL0020-6-421  |      1 |               nan |           0.011904 |       0.043808 |
    | MBSMPL0020-6-777  |      1 |               nan |           9.8e-05  |       0.000686 |
    | MBSMPL0020-6-1123 |      1 |               nan |           0.005603 |       0.201417 |
    | MBSMPL0020-6-1191 |      1 |               nan |           0.002578 |       0.368164 |
    | MBSMPL0020-6-263  |      1 |               nan |           0.004344 |       0.000381 |

    Into format:

    | sample_id         |   week | variable        |   value |
    |:------------------|-------:|:----------------|--------:|
    | MBSMPL0020-6-421  |      1 | Acidobacteriota |     nan |
    | MBSMPL0020-6-777  |      1 | Acidobacteriota |     nan |
    | MBSMPL0020-6-1123 |      1 | Acidobacteriota |     nan |
    | MBSMPL0020-6-1191 |      1 | Acidobacteriota |     nan |
    | MBSMPL0020-6-263  |      1 | Acidobacteriota |     nan |

    Args:
        data (pandas.DataFrame): see format above

    Returns:
        pandas.DataFrame: see format above
    &#34;&#34;&#34;
    melted = data.melt(id_vars=[&#39;sample_id&#39;, &#39;week&#39;])
    return melted</code></pre>
</details>
</dd>
<dt id="qbiome.data_formatter.DataFormatter.pivot_into_column_format"><code class="name flex">
<span>def <span class="ident">pivot_into_column_format</span></span>(<span>self, data)</span>
</code></dt>
<dd>
<div class="desc"><p>Pivot the input data frame from this format:</p>
<table>
<thead>
<tr>
<th align="left">sample_id</th>
<th align="right">subject_id</th>
<th align="left">variable</th>
<th align="right">week</th>
<th align="right">value</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Actinobacteriota</td>
<td align="right">27</td>
<td align="right">0.36665</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Bacteroidota</td>
<td align="right">27</td>
<td align="right">0.507248</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Campilobacterota</td>
<td align="right">27</td>
<td align="right">0.002032</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Desulfobacterota</td>
<td align="right">27</td>
<td align="right">0.005058</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-10</td>
<td align="right">1</td>
<td align="left">Firmicutes</td>
<td align="right">27</td>
<td align="right">0.057767</td>
</tr>
</tbody>
</table>
<p>Into this format where each column is a biome:</p>
<table>
<thead>
<tr>
<th align="left">sample_id</th>
<th align="right">week</th>
<th align="right">Acidobacteriota</th>
<th align="right">Actinobacteriota</th>
<th align="right">Bacteroidota</th>
</tr>
</thead>
<tbody>
<tr>
<td align="left">MBSMPL0020-6-421</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.011904</td>
<td align="right">0.043808</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-777</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">9.8e-05</td>
<td align="right">0.000686</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-1123</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.005603</td>
<td align="right">0.201417</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-1191</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.002578</td>
<td align="right">0.368164</td>
</tr>
<tr>
<td align="left">MBSMPL0020-6-263</td>
<td align="right">1</td>
<td align="right">nan</td>
<td align="right">0.004344</td>
<td align="right">0.000381</td>
</tr>
</tbody>
</table>
<h2 id="args">Args</h2>
<dl>
<dt><strong><code>data</code></strong> :&ensp;<code>pandas.DataFrame</code></dt>
<dd>see format above</dd>
</dl>
<h2 id="returns">Returns</h2>
<dl>
<dt><code>pandas.DataFrame</code></dt>
<dd>see format above</dd>
</dl></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def pivot_into_column_format(self, data):
    &#34;&#34;&#34;Pivot the input data frame from this format:

    | sample_id       |   subject_id | variable         |   week |    value |
    |:----------------|-------------:|:-----------------|-------:|---------:|
    | MBSMPL0020-6-10 |            1 | Actinobacteriota |     27 | 0.36665  |
    | MBSMPL0020-6-10 |            1 | Bacteroidota     |     27 | 0.507248 |
    | MBSMPL0020-6-10 |            1 | Campilobacterota |     27 | 0.002032 |
    | MBSMPL0020-6-10 |            1 | Desulfobacterota |     27 | 0.005058 |
    | MBSMPL0020-6-10 |            1 | Firmicutes       |     27 | 0.057767 |

    Into this format where each column is a biome:

    | sample_id         |   week |   Acidobacteriota |   Actinobacteriota |   Bacteroidota |
    |:------------------|-------:|------------------:|-------------------:|---------------:|
    | MBSMPL0020-6-421  |      1 |               nan |           0.011904 |       0.043808 |
    | MBSMPL0020-6-777  |      1 |               nan |           9.8e-05  |       0.000686 |
    | MBSMPL0020-6-1123 |      1 |               nan |           0.005603 |       0.201417 |
    | MBSMPL0020-6-1191 |      1 |               nan |           0.002578 |       0.368164 |
    | MBSMPL0020-6-263  |      1 |               nan |           0.004344 |       0.000381 |

    Args:
        data (pandas.DataFrame): see format above

    Returns:
        pandas.DataFrame: see format above
    &#34;&#34;&#34;
    # keep sample_id in here for later cohort identification
    pivoted = data.pivot_table(
        index=[&#39;sample_id&#39;, &#39;week&#39;], columns=[&#39;variable&#39;])[&#39;value&#39;].reset_index()
    pivoted.sort_values(by=[&#39;week&#39;], inplace=True)
    pivoted.reset_index(drop=True, inplace=True)
    return pivoted</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<img src="logozed_nowhite.png" alt="drawing" style="width:400px;"/>
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="qbiome" href="index.html">qbiome</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="qbiome.data_formatter.DataFormatter" href="#qbiome.data_formatter.DataFormatter">DataFormatter</a></code></h4>
<ul class="">
<li><code><a title="qbiome.data_formatter.DataFormatter.load_data" href="#qbiome.data_formatter.DataFormatter.load_data">load_data</a></code></li>
<li><code><a title="qbiome.data_formatter.DataFormatter.load_meta" href="#qbiome.data_formatter.DataFormatter.load_meta">load_meta</a></code></li>
<li><code><a title="qbiome.data_formatter.DataFormatter.melt_into_plot_format" href="#qbiome.data_formatter.DataFormatter.melt_into_plot_format">melt_into_plot_format</a></code></li>
<li><code><a title="qbiome.data_formatter.DataFormatter.pivot_into_column_format" href="#qbiome.data_formatter.DataFormatter.pivot_into_column_format">pivot_into_column_format</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
Authors: Lynn Zheng, Jin Li, Nicholas Sizemore, and Ishanu Chattopadhyay <a href="https://zed.uchicago.edu"> Zero Knowledge Discovery, University of Chicago</a>. Email: ishanu@uchicago.edu
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.10.0</a>.</p>
</footer>
</body>
</html>